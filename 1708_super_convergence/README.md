# [Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates](https://arxiv.org/abs/1708.07120)

Deep Learning Seminar 02.10.18

## TDLR

This paper describes a phenomenon, which named "super-convergence", where neural networks can be trained an order of magnitude faster than with standard training methods. The existence of super-convergence is relevant to understanding why deep networks generalize well.

## Notes

Bunch of experiments with cycle lr and variance of batch size with empirical studies on how it affects learning process and overall accuracy. Spoiler: cycle lr works well, increasing batch size also decrease variance when learning.

## Afterword

Impressive, but also pure technological breakthrough.

## Links

- [Now anyone can train Imagenet in 18 minutes](http://www.fast.ai/2018/08/10/fastai-diu-imagenet/)